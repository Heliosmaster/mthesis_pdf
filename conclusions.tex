\chapter{Conclusions and further developments} \label{chap:conclusions}

Our first goal was to investigate the possibility of performing sparse matrix partitioning in an iterative fashion, trying to establish a systematic approach on deciding which information has to be kept for an improvement on the quality of the solution, and what can be safely discarded; secondly, our intent was also to explore the possibilities for an improvement on the initial solution using the medium-grain model.

In this thesis, the difference between these two research directions was translated into the separation between partition-oblivious and partition-aware algorithms; moreover, we tried to apply the same principles (where possible) in order to come up with simple schemes that could be modified to serve either purpose. In the following sections we summarize our findings and try to envision possibile further developments in this field.

\section{Improvement of the initial solution} \label{sec:conclusions_po}

As already outlined in Section \ref{sec:mediumgrain}, for the medium-grain model the initial split of the matrix $A$ into $A_r$ and $A_c$ is of vital importance: our goal was to investigate whether the algorithm proposed by the authors in \cite{mediumgrain} was indeed a good choice.

To this purpose, we devised a number of different algorithms in Section \ref{sec:localview}, \ref{sec:hot_restart} and \ref{sec:is_vector} which exploited different features of the considered matrix. The first algorithm considered, \verb|po_localview|, turned out to be the best scheme among these partition-oblivious heuristics. 

This result is interesting from two different point of views, considering the fact that the \verb|po_localview| algorithm is a simplified version of the reference heuristic of \cite{mediumgrain}. Firstly, as this scheme does not include the iterative refinement procedure, briefly outlined in Section \ref{sec:preliminary_po}, it is not surprising at all that the final communication value is on average slightly worse (7\%) than the original heuristic. Secondly, as this method was still the best performing among the ones devised in this thesis, we have an additional motivation for the validity of the default algorithm for the medium-grain model.

\section{Iterative partitioning} \label{sec:conclusions_pa}

It is reasonable to assume that the initial split of the matrix $A$ into $A_r$ and $A_c$, can be done more efficiently with additional information, especially if the matrix $A$ has already been (bi)partitioned. In particular, we exploited the fact that if a row/column are uncut in $A$, it means that the partitioner decided, at some point in the previous iteration, that it was convenient for these nonzeros to be assigned to the same processor. This is a clear example of some information that might be interesting to preserve, and therefore the heuristics we developed in Chapters \ref{chap:methods} and \ref{chap:independent_set}, are aimed at giving a preference for these uncut row/columns, trying to keep them uncut also in the next iteration. Naturally, as it is not always possible to do (first of all because we are not directly assigning to processors, but rather to $A_r$ and $A_c$), a more complex approach is usually needed.

To this extent, a wide variety of heuristic has been devised: the partition-aware extension of the original algorithm, along with the heuristics that employ the Separated Block Diagonal of order 1 and 2 of the partitioned matrix $A$, quickly turned out to be far from effective. The other considered algorithms, instead, proved themselves much more interesting.

Albeit we were not able to devise a single scheme that outperforms \verb|medium-grain| for all the matrices involved in the testing, the results with rectangular matrices were quite encouraging. Chapter \ref{chap:independent_set} was focused on the concept of independent set, and the experimental results suggest that this is an interesting approach: our best heuristics (\verb|pa_localbest|, \verb|pa_is_1|, \verb|pa_is_3|) rely indeed on this concept, implicitly or explicitly. Even the simple concatenation of rows and columns in the priority vector $v$ can be intended as a special case of the ideas of Section \ref{sec:is_vector}: the set of rows (or columns) is as a matter of fact an independent set, albeit probably not of maximum cardinality. The improvement of the results of this heuristic with increasing rectangularity of the matrices is also to be seen in this perspective: the more one dimension is dominant, the more that set of indices has a cardinality closer to the maximum independent set computed on the graph constructed according to Section \ref{sec:is_graph}.

The experimental results confirmed our theoretical expectation that the indipendent set approach is indeed worthwile: considering only the rectangular matrices in our test bed, the results of these heuristics were better (albeit marginally) than \verb|medium-grain|.

\section{Further research}

Even though in Section \ref{sec:conclusions_po} we noted how the algorithm proposed in \cite{mediumgrain} is still the most efficient for splitting a matrix $A$ into $A_r$ and $A_c$ for the medium-grain model, after comparing it with many other different heuristics, it might still be convenient to research additional strategies, in order to find a more efficient method or gain additional confidence on this heuristic.

The partition-aware heuristics proposed in this thesis, are ment as a first attempt at a fully iterative approach at sparse matrix partitioning, and further research can easily be performed. It might be wortwhile to investigate in more depth the properties of the maximum independent set, in order to fully exploit the 2-Dimensionality of the medium-grain model.

In addition, the iterative refinement procedure described in \cite{mondriaan} might be extended also to our results, especially for the partition-aware heuristics.

Even though the implementation of the Hopcroft-Karp algorithm described in Section \ref{sec:hopcroft_karp} was successful in most cases (and it was performed in a reasonable amount of time even for the bigger matrices), it might still be wortwhile to produce a C implementation, in order to allow the eventual integration with the Mondriaan software package. In particular, it might be interesting to investigate our findings, with respect to rectangular matrices, in more depth: if we are able to get consistently better partitioning exploiting the computation of the maximum independent set, it might be possible to include the algorithm in the software partitioner: before applying any other technique, if the user decides to sacrifice computation time for a better partitioning, the software might try to recognize whether the considered matrix is strongly rectangular: if so, then our approach might be executed (after eventually leaving to the final user the choice).

