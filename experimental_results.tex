\chapter{Implementation and experimental results} \label{chap:experimental_results}

In Chapter \ref{chap:methods} and \ref{chap:independent_set} we discussed different heuristics to be used in the matrix partitioning problem. Whether we aim at improving the initial partitioning or a fully iterative procedure, we need to apply those ideas to practice, devising an efficient implementation.

In Section \ref{sec:earlier_work}, we mentioned existing software partitioners: Mondriaan \cite{mondriaan} is the package of our choice and we defer to it the actual computations of the partitionings, limiting ourselves to create the matrix $B$ of the medium grain model. Now, for sake of clarity, we give explicitly the computation of $B$ in Algorithm \ref{alg:B}. Note how we neglect completely the values of the nonzeros, only considering the sparsity pattern of $A$.

\begin{algorithm}[h]
	\begin{algorithmic}
		\Require{$A_r$, $A_c$}
		\Ensure{$B$}
		\State $B \gets \varnothing$
		\ForAll{$a_{ij} \in A_c$} \Comment{The part relative to $A_c$}
		\State $b_{i+n,j} = 1$
		\EndFor
		\ForAll{$a_{ij} \in A_r$} \Comment{The part relative to $A_r$}
		\State $b_{j,i+n} = 1$
		\EndFor
		\For{$j=1,\dots,n$} \Comment{Dummy nonzeros for cut columns}
		\If{$\exists\, i$ s.t. $a_{ij} \in A_r$ and $\exists\, i'$ s.t. $a_{i'j} \in A_c$}
		\State $b_{i,i} = 1$
		\EndIf
		\EndFor
		\For{$i=1,\dots,m$} \Comment{Dummy nonzeros for cut rows}
		\If{$\exists\, j$ s.t. $a_{ij} \in A_r$ and $\exists\, j$ s.t. $a_{ij'} \in A_c$}
		\State $b_{n+i,n+i} = 1$
		\EndIf
		\EndFor
	\end{algorithmic}
	\caption{Construction of $B$ following the medium-grain model.} \label{alg:B}
\end{algorithm}

Now, we can outline in more detail the general framework that we used to implement and test the heuristics described in the previous chapters, as done in Algorithm \ref{alg:framework}. The maximum number of iterations allowed, the parameter $iter_{max}$, is required for such algorithm.  

\begin{algorithm}[h]
	\begin{algorithmic}
		\Require{Sparse matrix $A$}
		\Ensure{Partitioning for the matrix $A$}
		\State Partition $A$ with Mondriaan using the default options and the medium grain model
		\For{$i=0,\dots,iter_{max}$}
		\State Use any of the heuristics described previously to compute $A_r$ and $A_c$
		\State compute $B$, using Algorithm \ref{alg:B}, from $A_r$ and $A_c$
		\State Partition $B$ with Mondriaan using the default options and the row-net model
		\State Re-construct $A$ with the new partitioning
		\EndFor
	\end{algorithmic}
	\caption{General framework for the testing of our heuristics} \label{alg:framework}
\end{algorithm}

Note that, as we made a distinction in Chapter \ref{chap:methods} and \ref{chap:independent_set} between partition-oblivious and partition-aware methods, Algorithm \ref{alg:framework} is suitable for both the research directions mentioned in Chapter \ref{chap:introduction}: even though the framework is naturally suited for developing a fully iterative scheme for sparse matrix partitioning, if we are after a better initial partitioning for the medium grain, we can simply neglect the partitioning done in the first step; this is precisely the scope for a partition-oblivious heuristic.

Regarding the actual implementation, we can see from Algorithm \ref{alg:framework} that Mondriaan is used for performing the actual partitioning; this is the ideal case for its use as a software library. As a consequence, we also used C as the main implementation language, even though MATLAB was used for faster prototyping: the flexibility added by managing objects at runtime  is ideal when designing algorithms. In order to have C code and MATLAB code interact in the correct way, we used MEX files \cite{mex}. In general, unless preliminary tests showed that the considered heuristic had a remarkably bad quality, we translated back everything to the C language, in order to remove the MEX layer of complexity and get a more efficient implementation.

The matrices used to test the effectiveness of the discussed heuristics are mainly from the University of Florida Sparse Matrix Collection \cite{ufl}, and some can also be found on the Matrix Market collection \cite{matrixmarket}. 

Table \ref{tab:matrices} provides a more thorough description of the matrices used, along with an outline of their basic properties (number of rows $m$, number of columns $n$, number of nonzeros $N$) and their original purpose. Some of these matrices (namely the ones with the $\dagger$ symbol in the table) belong to the 10th Dimacs Implementation Challenge \cite{dimacs}, which addressed the graph partitioning and graph clustering problem, and are therefore naturally suited for testing the quality solutions of our algorithms.

\begin{table}[h]
	\centering
	\begin{tabular}{|l|r|r|r|p{7cm} |}
		\hline	
		\textbf{Name} & \textbf{$m$} & \textbf{$n$} & \textbf{$N$} & \textbf{Source problem} \\ \hline
		\verb|lpi_ceria3d| 									& 3576 		& 4400 		& 21178 & Netlib Linear Programming \\
		\verb|dfl001| 											& 12230 	& 6071 		& 35632 & Netlib Linear Programming \\ 
		\verb|delaunay_n15| $\dagger$ 			& 32768 	& 32768 	& 196548 & Delaunay triangulations of random points in plane \\ 
		\verb|deltaX| 											& 68600 	& 21961 	& 247424 & High fillin with exact partial pivoting \\
		\verb|cre_b| 												& 9648 		& 77137 	& 260785 & Netlib Linear Programming \\ 
		\verb|tbdmatlab| 										& 19859 	& 5979 		& 430171 & Term-by-document matrix \\ 
		\verb|nug30| 												& 52260 	& 379350 	& 1567800 & Netlib Linear Programming \\ 
		\verb|coAuthorsCiteseer| $\dagger$ 	& 227320 	& 227320 	& 1628268 & Citation and coauthor network\\ 
		\verb|bcsstk32| $\dagger$ 					& 44609 	& 44609 	& 2014701 & Stiffness matrix for automobile chassis \\ 
		\verb|bcsstk30| $\dagger$						& 28924 	& 28924 	& 2043492 & Stiffness matrix for off-shore generator platform \\
		\verb|c98a| 												& 56243 	& 56274 	& 2075889 & Factorization of composite integers with 98 decimal digits  \\ 
		\verb|wave| 	$\dagger$							& 156317 	& 156317 	& 2118662 & 3D finite elements \\
		\verb|tbdlinux| 										& 112757 	& 20167 	& 2157675 & Term-by-document matrix \\
		\verb|stanford| 										& 281903 	& 281903 	& 2312497 & Links between pages in Stanford website \\
		\verb|rgg_n_2_18_s0| $\dagger$ 			& 262144 	& 262144 	& 3094566 & Random graph \\
		\verb|polyDFT| 											& 46176 	& 46176 	& 3690048 & Polymer self-assembly \\ 
		\verb|cage13| 											& 445315 	& 445315 	& 7479343 & DNA Electrophoresis \\
		\verb|stanford_berkeley| 						& 683446 	& 683446 	& 7583376 & Links between Stanford and Berkeley websites \\
		\hline
	\end{tabular}
	\caption{Matrices used in our experiments} \label{tab:matrices}
\end{table}

The parameter $iter_{max}$ of Algorithm \ref{alg:framework} is of vital importance for the running time of our iterative method: it is true that our research motivation is to trade computation time for solution quality, but we are after the most efficient way to do so. Therefore, an iterative scheme that improves the quality of the solution very slowly (thus needing a high $iter_{max}$ to improve as much as possible) is not desirable; fortunately, preliminary tests showed that our heuristic are indeed very fast in this aspect and only one iteration is needed: additional iterations either improve the solution quality by a very small amount (which likely depends on the probabilistic nature of the heuristic and the partitioner) or produce the opposite effect, resulting in a much worse solution. Table \ref{tab:iterations} shows an example of multiple iterations for some of the described heuristic.

\begin{table}[h]
	\centering
	\begin{tabular}{|l|c||c|c|c|c|c|c|c|c|c|c|}
		\hline
		\multirow{2}{*}{\textbf{Heuristic}} & \multicolumn{11}{c|}{\textbf{Iterations}} \\ \cline{2-12} 
		& 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\ \hline
		\verb|po_localview| & 599 & 575 & 576 & 578 & 573 & 583 & 578 & 574 & 575 & 578 & 573 \\
		\verb|pa_localview| & 588 & 577 & 580 & 577 & 577 & 574 & 578 & 580 & 576 & 579 & 575  \\
 \verb|sbdview| & 590 & 588 & 591 & 579 & 597 & 595 & 589 & 603 & 595 & 589 & 587 \\
 \verb|po_unsorted_concat| & 579 & 597 & 594 & 593 & 593 & 597 & 597 & 598 & 594 & 603 & 596 \\ 
		\hline
	\end{tabular}
	\caption{Multiple iterations of four different heuristics for the test matrix \texttt{dfl001}. The numbers shown are the rounded arithmetic means of each iteration over 10 repeats of the experiment. Iteration 0 stands for the initial partitioning obtained with the medium-grain model. } \label{tab:iterations}
\end{table}



\section{Improving the initial partitioning}
\section{Fully iterative partitioning}



